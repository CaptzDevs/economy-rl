import { citizens } from "./data/sampleAgents.js";
import { tick } from "./sim/tick.js"; // ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô async function
import {  createQModel, loadModel, loadShareMemory, saveModel, saveSharedMemory } from "./strategy/dqn.js";
import { trainFromLogs, setTrainedModel } from "./strategy/neuralTf.js";
import fs from "fs";
import { loadJSON, saveJSON } from "./utils/file.js";
import chalk from "chalk";
import ora from 'ora';
import { waitWithSpinner } from "./utils/loading.js";


const result_path = "./model/modelResult.json";

function sleep(ms) {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

async function runSimulation(steps = 10, delay = 500, callback) {
  let i = 0;
  for (i; i < steps; i++) {
    const aliveCitizens = citizens.filter((c) => c.alive);

    if (aliveCitizens.length === 0) {
      console.log(`\n‚ùå ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏¢‡∏∏‡∏î simulation ‡∏ó‡∏µ‡πà Tick ${i + 1}`);
      break;
    }

    console.clear();
    callback(i);
    console.log(`üìÜ Tick ${i + 1} | ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ ${aliveCitizens.length} ‡∏Ñ‡∏ô`);
    await tick(aliveCitizens); // ‡∏£‡∏≠ tick ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö async)
    await sleep(delay);
  }

  return i;

  /* console.log('\nüß† Logs ‡∏Ç‡∏≠‡∏á Agent ‡πÅ‡∏£‡∏Å:', citizens[0]?.memory.logs || '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•'); */
}


async function runIndividalDQN(epochs = 3) {
  for (let epoch = 0; epoch < epochs; epoch++) {
    const sum = [];
    const rewards = [];
    let oldMoney = 0;

    const sharedMemory = await loadShareMemory()
    const trainedModel = await loadModel();

        const epsilon = trainedModel ? 0.1 : Math.max(0.1, 1.0 - epoch * 0.2);

      for (const c of citizens) {
        c.strategy = "dqn";
        c.state.hunger = 100;
        c.state.energy = 100;
        c.state.happiness = 100;
        c.state.health = 100;
        c.money = epoch === 0 ? 100 : oldMoney;
        c.inventory.food = 1;
        c.alive = true;
        c.memory.logs = [];
        c.actionIndex = 0;
        c.totalReward = 0;
        c.epsilon = epsilon;
        c.age = 1;
        c.model = trainedModel ?? createQModel();
        
        c.replayBuffer = sharedMemory ?? [];
        // ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏¢‡∏Å: await loadModel(`file://./model/${c.name}/model.json`)
      }

     
      const trainedTick = await runSimulation(1000, 0, (tick) => {
        console.log("epoch :", epoch+1)
        if (tick % 10 === 0 && tick > 0) {
          citizens.forEach((c) => c.age++);
        }
         console.log(
        `üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏° Simulation ‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà ${epoch + 1} (Œµ = ${epsilon.toFixed(2)})`
      );
      });

      sum.push(citizens[0].age);
      rewards.push(citizens[0].totalReward);
      oldMoney = citizens[0].money;

    citizens.forEach((c) => {
      //console.log(`${c.name} action summary:`, summarizeActions(c.memory.logs));
    });

    // ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏£‡∏∞‡∏ö‡∏ö compareModelPerformance ‡πÅ‡∏ö‡∏ö‡∏£‡∏ß‡∏°:
    const bestAgent = await compareMultipleModelPerformance(citizens);
    if (bestAgent) {
      // ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å save model ‡πÅ‡∏¢‡∏Å per agent:
      await saveModel(citizens[bestAgent.index].model, `file://./model`);
    }
    if(epoch < epochs-1 ){
      await waitWithSpinner('Waiting for next epoch...', 3000, '‚úÖ Next epoch started!');
    }
  }
    console.log('üèÅ Simulation completed!');

}

runIndividalDQN(20);

const compareMultipleModelPerformance = async (agents) => {
  console.log(
    agents.map((item) => ({ age: item.age, reward: item.totalReward }))
  );

  const bestIndex = agents.reduce(
    (bestIdx, agent, idx, arr) =>
      agent.totalReward > arr[bestIdx].totalReward ? idx : bestIdx,
    0
  );

  const bestAgent = agents[bestIndex];
  const queryBestAgent = {
    index: bestIndex,
    name: bestAgent.name,
    age: bestAgent.age,
    reward: bestAgent.totalReward,
  };
  
  try {
    console.log("\n---------Compare Model Performance-----------");
    console.log("üèÜ Best Agent:", queryBestAgent.name);
    const savedResult = await loadJSON(result_path);
    if (savedResult) {
      
        const ageColor = queryBestAgent.age >= savedResult.age ? chalk.green : chalk.red;
        const rewardColor = queryBestAgent.reward >= savedResult.reward ? chalk.green : chalk.red;

        console.log(`üìà Age: ${savedResult.age.toFixed(2)} -> ${ageColor(queryBestAgent.age.toFixed(2))}`);
        console.log(`ü•á Reward: ${savedResult.reward.toFixed(2)} -> ${rewardColor(queryBestAgent.reward.toFixed(2))}`);

      if (
        queryBestAgent.age > savedResult.age 
      ) {
        saveJSON(result_path, queryBestAgent);
        saveSharedMemory(bestAgent.replayBuffer)
        console.log(chalk.green("‚úÖ Model result : Better"));
        return queryBestAgent;
      } else {
        console.log(chalk.red("‚ùå Model result : Bad"));
        return false;
      }
    } else {
      throw Error("No Save Model Result");
    }
  } catch (err) {
    // ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏ü‡∏•‡πå performance ‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏°‡πà‡∏°‡∏µ => ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
    console.log("‚ùå Err :", err.message);
    saveJSON(result_path, queryBestAgent);
    saveSharedMemory(bestAgent.replayBuffer)
    console.log("üìÑ No Model Result : Create new ");
    return queryBestAgent;
  }
};




async function runDQN(epochs = 3) {
  for (let epoch = 0; epoch < epochs; epoch++) {
    const sum = [];
    const rewards = [];
    let oldMoney = 0;
    let isFirstTrain = true;
    try {
      console.log("üíæ Loading Exist model...");
      await sleep(3000);
      await loadModel(); // ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏° ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
      isFirstTrain = false;
    } catch {
      console.log("üì¶ No Existing Model => Create New");
      await sleep(3000);
      initDQN(); // ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠
    }

    for (let index = 0; index < 1; index++) {
      const epsilon = Math.max(0.1, 1.0 - index * 0.2); // üîª ‡∏•‡∏î epsilon

      citizens.forEach((c) => {
        c.strategy = "dqn";
        c.state.hunger = 100;
        c.state.energy = 100;
        c.state.happiness = 100;
        c.state.health = 100;
        c.money = index === 0 ? 100 : oldMoney;
        c.inventory.food = 1;
        c.alive = true;
        c.memory.logs = [];
        c.actionIndex = 0;
        c.totalReward = 0;
        c.epsilon = epsilon;
        c.age = 1;
      });

      console.log(
        `üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏° Simulation ‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà ${index + 1} (Œµ = ${epsilon.toFixed(2)})`
      );

      const trainedTick = await runSimulation(1000, 0, (tick) => {
        if (tick % 10 === 0) {
          citizens.forEach((c) => c.age++);
        }
      });

      sum.push(citizens[0].age);
      rewards.push(citizens[0].totalReward);
      oldMoney = citizens[0].money;
    }

    // üìä ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏£‡∏ß‡∏°
    console.log("\n\n-----------Result-----------");
    console.log("ü§ñ ‡∏à‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß");
    console.log("üìà ‡∏≠‡∏≤‡∏¢‡∏∏‡∏£‡∏ß‡∏°‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö:", sum);
    console.log("ü•á Reward ‡∏£‡∏ß‡∏°‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö:", rewards);
    if ((await compareModelPerformance({ sum, rewards })) || isFirstTrain) {
      // üíæ Save Model
      await saveModel();
      console.log("ü§ñ Saved Model");
    }

    // üß† ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞ agent
    citizens.forEach((c) => {
      console.log(`${c.name} age: ${c.age} reword : ${c.totalReward}`);
      /* console.log(`${c.name} action summary:`, summarizeActions(c.memory.logs)); */
    });
    await sleep(5000);
  }
}

/* runDQN(20); */

const compareModelPerformance = async (newResult) => {
  try {
    const result = await loadJSON(result_path);

    console.log(newResult.map((item) => item.age));
    console.log(newResult.map((item) => item.totalReward));

    const totalAge = result.sum.reduce((a, b) => a + b, 0);
    const totalNewAge = newResult.sum.reduce((a, b) => a + b, 0);
    const totalReward = result.rewards.reduce((a, b) => a + b, 0);
    const totalNewReward = newResult.rewards.reduce((a, b) => a + b, 0);

    console.log("\n\n---------Compare Model Performance-----------");

    console.log("üìà Old Age:", result.sum);
    console.log("ü•á Old Reward:", result.rewards);
    // ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö performance ‡πÄ‡∏î‡∏¥‡∏°‡∏Å‡∏±‡∏ö‡πÉ‡∏´‡∏°‡πà

    if (totalNewAge > totalAge && totalNewReward > totalReward) {
      saveJSON(result_path, newResult);
      console.log(chalk.green("‚úÖ Model result : Better"));
      return true;
    } else {
      console.log(chalk.red("‚ùå Model result : Bad"));

      return false;
    }
  } catch (err) {
    // ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏ü‡∏•‡πå performance ‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏°‡πà‡∏°‡∏µ => ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
    saveJSON(result_path, newResult);
    console.log("üìÑ No Model Result : Create new ");
    return false;
  }
};

async function runNN() {
  // 0. ‡πÉ‡∏ä‡πâ behavior tree ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ log
  const sum = [];
  const logs = [];
  citizens.forEach((c) => (c.strategy = "dqn"));

  // 1. ‡πÄ‡∏Å‡πá‡∏ö logs
  const trainedTick = await runSimulation(1000, 0);
  sum.push(trainedTick);

  const trainedLogs = citizens[0].memory.logs;
  for (let index = 0; index < 5; index++) {
    const logs = citizens[0].memory.logs;
    const result = await trainFromLogs(trainedLogs);

    if (!result) {
      console.error("‚ùå ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (log ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏û‡∏≠)");
      return;
    }

    const { model, ACTIONS } = result;
    // 3. ‡∏ï‡∏±‡πâ‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
    setTrainedModel(model, ACTIONS);

    // 4. ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï agent
    citizens.forEach((c) => {
      c.strategy = "nn"; // ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß
      c.state.hunger = 100;
      c.state.energy = 100;
      c.state.happiness = 100;
      c.state.health = 100;
      c.money = 100;
      c.inventory.food = 1;
      c.alive = true;
      c.memory.logs = [];
      c.actionIndex = 0;
    });

    // 5. ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏£‡∏≠‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•
    console.log(`\nü§ñ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß`);
    sum.push(await runSimulation(1000, 0));
  }
  console.log("\n\nü§ñ ‡∏à‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß", sum);
  console.log(
    "\n\nü§ñ AGV.",
    (sum.reduce((a, b) => a + b, 0) / sum.length).toFixed(2)
  );

  console.log(summarizeActions(trainedLogs));
}

/* runNN(); */

function summarizeActions(logs) {
  const summary = {};

  for (const log of logs) {
    const action = log.action;
    if (!action) continue;

    if (!summary[action]) {
      summary[action] = 0;
    }

    summary[action]++;
  }

  return summary;
}
