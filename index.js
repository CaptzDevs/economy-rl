import { citizens } from './data/sampleAgents.js';
import { tick } from './sim/tick.js';  // ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô async function
import { initDQN } from './strategy/dqn.js';
import { trainFromLogs, setTrainedModel } from './strategy/neuralTf.js';
import fs from 'fs';

function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

async function runSimulation(steps = 10, delay = 500, callback) {
  let i = 0
  for (i; i < steps; i++) {
    const aliveCitizens = citizens.filter(c => c.alive);

    if (aliveCitizens.length === 0) {
      console.log(`\n‚ùå ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏¢‡∏∏‡∏î simulation ‡∏ó‡∏µ‡πà Tick ${i + 1}`);
      break;
    }

    console.clear();
    callback(i)
    console.log(`üìÜ Tick ${i + 1} | ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ ${aliveCitizens.length} ‡∏Ñ‡∏ô`);
    await tick(aliveCitizens);  // ‡∏£‡∏≠ tick ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö async)
    await sleep(delay);
  }

  return i

  /* console.log('\nüß† Logs ‡∏Ç‡∏≠‡∏á Agent ‡πÅ‡∏£‡∏Å:', citizens[0]?.memory.logs || '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•'); */
}




async function runDQN() {
  initDQN();  // ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• DQN ‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ
  const sum = []
  const rewards = []
  let oldMoney = 0
  for (let index = 0; index < 5; index++) {

  citizens.forEach(c => {
    c.strategy = 'dqn'; // ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß
    c.state.hunger = 100;
    c.state.energy = 100;
    c.state.happiness = 100;
    c.state.health = 100;
    c.money = index === 0 ? 100 : oldMoney;
    c.inventory.food = 1;
    c.alive = true;
    c.memory.logs = [];
    c.actionIndex = 0;
    c.totalReward = 0;  // üëà reset reward
    c.epsilon = 0.5//1.0 - index * 0.2;
    c.age = 1
  });

  console.log('üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏° simulation ‡∏î‡πâ‡∏ß‡∏¢ DQN');
   const trainedTick = await runSimulation(1000, 0 , (tick)=>{
    console.log(`üß¨ Gen : ${index+1}`)
    citizens.forEach(c => {
      c.age += tick%10 === 0 ? 1 : 0
    });
   });
   sum.push(citizens[0].age)
   rewards.push(citizens[0].totalReward)
   oldMoney = citizens[0].money


  }
  
  citizens.forEach(c => {
    console.log(`${c.name} action summary:`, summarizeActions(c.memory.logs));
  });
  
  console.log("\n\n-------------------")
  console.log('\n\nü§ñ ‡∏à‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß')
  console.log('üìà ‡∏£‡∏ß‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß', sum)
  console.log('ü•á ‡∏à‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß', rewards)



}

runDQN()


async function runNN() {
  // 0. ‡πÉ‡∏ä‡πâ behavior tree ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ log
  const sum = []
  const logs = []
  citizens.forEach(c => c.strategy = 'dqn');

  // 1. ‡πÄ‡∏Å‡πá‡∏ö logs
  const trainedTick = await runSimulation(1000, 0);
  sum.push(trainedTick)

  const trainedLogs = citizens[0].memory.logs;
  for (let index = 0; index < 5; index++) {
      
    
    const logs = citizens[0].memory.logs;
    const result = await trainFromLogs(trainedLogs);

    if (!result) {
      console.error('‚ùå ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (log ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏û‡∏≠)');
      return;
    }

    const { model, ACTIONS } = result;
    // 3. ‡∏ï‡∏±‡πâ‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
    setTrainedModel(model, ACTIONS);

    // 4. ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï agent
    citizens.forEach(c => {
      c.strategy = 'nn'; // ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß
      c.state.hunger = 100;
      c.state.energy = 100;
      c.state.happiness = 100;
      c.state.health = 100;
      c.money = 100;
      c.inventory.food = 1;
      c.alive = true;
      c.memory.logs = [];
      c.actionIndex = 0;
    });

    // 5. ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏£‡∏≠‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•
    console.log(`\nü§ñ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß`);
    sum.push( await runSimulation(1000, 0))
    

  }
  console.log('\n\nü§ñ ‡∏à‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß', sum)
  console.log('\n\nü§ñ AGV.',( sum.reduce((a, b) => a + b, 0) / sum.length).toFixed(2))


  console.log(summarizeActions(trainedLogs))
}

/* runNN(); */

function summarizeActions(logs) {
  const summary = {};

  for (const log of logs) {
    const action = log.action;
    if (!action) continue;

    if (!summary[action]) {
      summary[action] = 0;
    }

    summary[action]++;
  }

  return summary;
}

